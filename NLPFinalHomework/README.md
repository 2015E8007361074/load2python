==README

    小组名称：NLP学习小组
    小组选题：实现一个基于文本内容/情感的文本自动分类系统（Text classification）
    题目要求：依据某种文本分类标准实现一个文本自动分类系统。针对汉语文本或英语文本均可。
    小组成员：四人    
    余文艳 姚攀 林正日 王慈枫    
    时间截止：2016年7月17号

**需要提交：技术报告+系统代码+可执行程序**

1.技术报告包括<br>

    项目目标，
    国内外相关工作，
    自己在项目中的承担工作的不同点，
    实现系统的核心思想和算法描述，
    系统的主要模块流程，
    实验结果及分析。

2.系统代码：目前的想法是使用Python对开源的数据集进行文本分类，分词这一块采用开源的结巴分词模块，学习算法初步决定采用决策树C4.5算法，最终的系统实现可以对测试集的文本进行自动分类。<br>
3.可执行程序。直接提交Python代码或者打包成跨平台安装程序均可。<br>


需要做的工作：文献查找，算法设计，代码编写，系统测试，技术报告的编写

==============================================================================================
#### 开发日志

#### _训练过程_

##### **第一步，数据切割。**<br>
file:dataCut.py<br>

由于80万训练集以及20万测试集样本数据过大，单机上用于前期的算法开发不太方便，因此先对80万训练集切割出10万数据集作为算法开发用。<br>
8万标注好的短信数据集由于训练分类模型.<br>
2万样本短信数据集由于测试用，其中标签提取出来用于后面计算分类的准确率，方便模型评估。<br>

##### **第二步，文本分词。**<br>
file：seg_word.py<br>

这里采用开源的结巴分词系统，用于本系统的分词。

##### **第三步，基于TF-IDF算法，构建垃圾词汇库**<br>

##### **第四步，特征提取**<br>

##### **第五步，使用决策树算法构建分类模型**<br>

#### _分类过程_

##### **第一步，文本分词。**<br>
这里采用开源的结巴分词系统，用于本系统的分词。

##### **第二步，特征提取。**<br>

##### **第三步，利用训练好的分类模型，对测试样本数据进行分类。**<br>

##### **第四步，模型性能的评估**<br>







